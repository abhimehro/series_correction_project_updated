{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Workflow: Seatek Series Correction\n",
    "\n",
    "This notebook demonstrates how to use the `seatek-correction` command-line tool and potentially interact with the underlying Python modules (`batch_correction`, `processor`) for processing Seatek sensor data.\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "1.  The `seatek-series-correction` package must be installed (`pip install -e .` in the project root).\n",
    "2.  **Sample data files** (e.g., `S26_Y01.txt`, `S27_Y01.txt`) must be present in the `./data/` directory relative to where this notebook or the CLI command is run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using the Command-Line Interface (CLI)\n",
    "\n",
    "The primary way to run the batch processing is via the `seatek-correction` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the current working directory is the project root if necessary\n",
    "# import os\n",
    "# print(os.getcwd())\n",
    "# os.chdir('path/to/project/root') # Adjust if needed\n",
    "\n",
    "# Example: Run correction for Series 26, Years 1995-1996, River Miles 54.0-53.0\n",
    "# This assumes sample files like data/S26_Y01.txt and data/S26_Y02.txt exist\n",
    "\n",
    "# Define command arguments\n",
    "series = 26\n",
    "rm_start = 54.0\n",
    "rm_end = 53.0\n",
    "year_start = 1995\n",
    "year_end = 1996\n",
    "output_dir = './output_notebook_example/' # Specify a dedicated output directory\n",
    "config_file = 'scripts/config.json' # Use default config\n",
    "\n",
    "# Construct the command\n",
    "command = (\n",
    "    f\"seatek-correction \"\n",
    "    f\"--series {series} \"\n",
    "    f\"--river-miles {rm_start} {rm_end} \"\n",
    "    f\"--years {year_start} {year_end} \"\n",
    "    f\"--output {output_dir} \"\n",
    "    f\"--config {config_file}\"\n",
    ")\n",
    "\n",
    "print(f\"Running command:\n{command}\n\")\n",
    "\n",
    "# Execute the command using the shell\n",
    "# Note: This requires the package to be installed\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the command, check the specified `output_dir` (`./output_notebook_example/`) for:\n",
    "\n",
    "* Corrected data files (e.g., `S26_Y01_1995_CorrectedData.csv`, `S26_Y02_1996_CorrectedData.csv`)\n",
    "* The summary report (`Batch_Processing_Summary.csv`)\n",
    "\n",
    "Also check the log file (`processing_log.txt` in the project root by default) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Display the summary report generated by the last run\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "summary_path = os.path.join(output_dir, 'Batch_Processing_Summary.csv')\n",
    "\n",
    "try:\n",
    "    summary_df = pd.read_csv(summary_path)\n",
    "    print(\"Processing Summary:\")\n",
    "    display(summary_df)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Summary file not found at {summary_path}. Ensure the CLI command ran successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the Python Modules Directly (Advanced)\n",
    "\n",
    "You can also import and use the `batch_correction` and `processor` modules directly within Python scripts or notebooks. This allows for more customization or integration into larger workflows." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import batch_correction\n",
    "from scripts import processor\n",
    "from scripts import loaders\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Configure logging if needed (batch_process usually configures it)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Example: Process a single known data file --- \n",
    "\n",
    "# 1. Load Configuration\n",
    "try:\n",
    "    config = loaders.load_config('scripts/config.json')\n",
    "    # Add river mile map if needed\n",
    "    rm_map_path = config.get(\"RIVER_MILE_MAP_PATH\", \"scripts/river_mile_map.json\")\n",
    "    if os.path.isfile(rm_map_path):\n",
    "         with open(rm_map_path, 'r') as f_map:\n",
    "              rm_data = json.load(f_map)\n",
    "              config[\"SENSOR_TO_RIVER\"] = rm_data.get(\"SENSOR_TO_RIVER\", {})\n",
    "              config[\"RIVER_TO_SENSORS\"] = rm_data.get(\"RIVER_TO_SENSORS\", {})\n",
    "except Exception as e:\n",
    "    print(f\"Error loading config: {e}\")\n",
    "    config = {} # Fallback to empty config\n",
    "\n",
    "# 2. Define file path (Requires sample data!)\n",
    "sample_file_path = 'data/S26_Y01.txt' # ADJUST THIS PATH\n",
    "\n",
    "if not os.path.exists(sample_file_path):\n",
    "    print(f\"ERROR: Sample file not found at {sample_file_path}. Cannot proceed with direct processing example.\")\n",
    "else:\n",
    "    # 3. Load Raw Data (using the internal loader from batch_correction)\n",
    "    try:\n",
    "        raw_df = batch_correction._load_raw_data(sample_file_path)\n",
    "        print(f\"Loaded raw data from {sample_file_path}:\")\n",
    "        display(raw_df.head())\n",
    "        \n",
    "        # 4. Process Data using the processor module\n",
    "        if not raw_df.empty:\n",
    "            processor_config = config.get(\"processor_config\", {})\n",
    "            processor_config.update(config.get(\"defaults\", {}))\n",
    "            \n",
    "            corrected_df = processor.process_data(raw_df.copy(), config=processor_config)\n",
    "            print("\nProcessed data:")\n",
    "            display(corrected_df.head())\n",
    "            \n",
    "            # 5. Further Analysis / Visualization (Example)\n",
    "            try:\n",
    "                import matplotlib.pyplot as plt\n",
    "                \n",
    "                plt.figure(figsize=(12, 6))\n",
    "                # Assuming 'Time (Seconds)' and the auto-detected value column\n",
    "                time_col = processor_config.get('time_col', 'Time (Seconds)')\n",
    "                value_col = processor_config.get('value_col')\n",
    "                if not value_col: # Find first non-time numeric col if not set\n",
    "                     import numpy as np\n",
    "                     numeric_cols = corrected_df.select_dtypes(include=np.number).columns\n",
    "                     value_col = [col for col in numeric_cols if col != time_col][0]\n",
    "                     \n",
    "                plt.plot(raw_df[time_col], raw_df[value_col], label='Raw Data', alpha=0.7, marker='.', linestyle='-')\n",
    "                plt.plot(corrected_df[time_col], corrected_df[value_col], label='Corrected Data', alpha=0.8, marker='.', linestyle='-')\n",
    "                plt.title(f\"Raw vs Corrected Data - {os.path.basename(sample_file_path)}\")\n",
    "                plt.xlabel(time_col)\n",
    "                plt.ylabel(value_col)\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "            except ImportError:\n",
    "                print("\nMatplotlib not installed. Skipping plot.")\n",
    "            except Exception as plot_err:\n",
    "                 print(f"\nError during plotting: {plot_err}\")\n",
    "\n",
    "    except batch_correction.ProcessingError as load_err:\n",
    "        print(f\"Error loading data: {load_err}\")\n",
    "    except Exception as proc_err:\n",
    "        print(f\"Error processing data: {proc_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This direct module usage allows for fine-grained control, debugging, and integration into other Python workflows, but requires careful handling of configurations and file paths."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
